
<head>
    <meta charset='UTF-8'/>
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel='stylesheet' href='styles.css'/>
    <link href="//db.onlinewebfonts.com/c/86e4910dca09b21de768cb0714d40970?family=Photina" rel="stylesheet" type="text/css"/>
    <title>Becky and Alex's 152 Project Introduction and Related Works</title>
    <link rel="shortcut icon" type="image/x-icon" href="favicon.ico">
  </head>
  
  <body>
    <div class="main">
      <sidebar>
      </sidebar>
      <div class="page">
        <h2>Neural Networks Introduction and Related Works</h2>
        <h3>An ethical investigation into Spotify recommendations</h3> 
        <p>Becky Zhang and Alex Franklin | March 17, 2021</p>
          
          <h2> Introduction </h2>
          <p> 
              Much of our consumption of music is dictated by the algorithms and models behind streaming service recommendations, which are impacted by the user data that they collect. The architecture of these models, and biases in their data, has real-life implications on what music is played. To investigate these implications, we need to understand what models are used by Spotify, as well as what data is collected and how it is used.
          </p>
          <p>
              The three methods Spotify uses in its recommendation system are collaborative filtering, natural language processing (NLP), and content-based models. Collaborative filtering is content-agnostic, meaning it doesn’t use information related to the music itself, but instead looks at the consumption patterns associated with it. NLP uses song titles, artists, and other textual evidence such as summaries, reviews, tags, etc. to inform its recommendations. Content-based methods use the audio signal of the music to create models, for example training a convolutional neural network (CNN) to recognize certain patterns in the music itself.
          </p>
          <p>
              One challenge that recommendation algorithms face is the positive feedback loop wherein existing user data for certain songs/artists help to drive users toward the very same content (thus generating more data which does the same, and so on so forth). The lack of data for less popular or newer music is called the “cold start problem”, which renders certain songs and artists as outliers that are less easily recommendable by collaborative filtering or NLP models. One solution to this is to include the use of CNNs in addition to collaborative filtering and NLP, and sharpening their capabilities to identify outliers and edge cases. 
          </p>
          <p>
              Another challenge is a lack of access to what Spotify’s neural networks actually look like. We aim to counter this by looking into a variety of applications for content-based models that similarly take audio fragment inputs and learning about what their biases or flaws are. Additionally, we’ll investigate NLP and collaborative filtering and how their developers have tried to combat their blindspots. We will also analyze a long blog post by a former Spotify intern about their insider knowledge on the company’s NNs, and relevant research papers that make use of Spotify’s data.
          </p>
          <p>
              We will first have to develop a more concrete understanding of how these neural networks are functioning (what kind of data and tools they're using) and the goals and decision-making processes of Spotify's development team, to the best of our ability. We will review available research related to Spotify’s recommendation procedures and examine them through a technical and ethical lens. Our hope is to unpack how Spotify uses neural networks to generate music recommendations; identify key blind spots and biases; and assess the broader ethical implications of these, proposing solutions where possible.
          </p>
          
          <h2> Related Works </h2>
          <p>
                  <a href="https://web.stanford.edu/~rezab/nips2014workshop/submits/logmat.pdf">Logistic Matrix Factorization for Implicit
                      Feedback Data</a> <br>
                  This Stanford research paper by a Spotify engineer presents logistic matrix factorization as a tool for collaborative filtering, one of the three deep learning tools Spotify uses to make recommendations based on implicit user feedback data. This offers a more concrete explanation of one way to effectively conduct collaborative filtering.
            <br><br>
                  <a href="https://dl.acm.org/doi/abs/10.1145/3366423.3380281?casa_token=vDRONauZb0oAAAAA:7WQ_BxL-nXgJPL4d2jPLyL9N9avIMfEWW5iJ7roEMjDBN7SxPQHfm0kspK_LuBipr9x7N9Yi4p90YQ">
                      Algorithmic Effects on the Diversity of Consumption on Spotify</a> <br>
                  This research article highlights a key flaw to collaborative filtering models: their reliance on existing implicit user data generates recommendations biased toward older and more popular songs, compromising and actively reducing the diversity of music which people using their recommendations consume. 
          </p>
          
           <h2> Project Update 2 </h2>
          
          <p>
               For this update we read more in-depth the research articles in our related works section and thought of some critiques and lines of questioning
              we can continue to look into based on what we read.
          </p>
          <ul>
              <li>The issue about diversity isn’t retaining listeners on the platform, but more about how it affects which artists are listened to.</li>
              <li>What are the disadvantages of increasing user listening rates in general?</li>
              <li>What are the specialists listening to? (aka when is specialism OK? → could diversifying our music tastes potentially be a way of neutralizing/numbing it?)</li>
              <li>How do we define diversity in the most ethical way? (new/smaller artists, $$) And how can we empirically delineate this diversity?</li>
              <li> Is general musical diversity changing? If so, how much does this influence GS scores and the way we interpret them?</li>
              <li> What are the causes behind people choosing to consume music organically vs algorithmically?</li>
              <li>(Big data and privacy concerns—the backbone of implicit feedback mechanisms)</li>
          </ul>
                    
          <h4> Things to investigate next </h4>
          <p>
              Our ethical goals for a streaming platform’s algorithmic recommendations (i.e. how to define the diversity we want to strive toward?)
              <br><br>
              What would a diversity-aware recommendations algorithm look like? Is such a model even attainable, 
              and if so would it be effective in achieving our ethical goals? (read Spotify diversity paper’s sources 
              [1], [7], [32], [30]) (look for Discover-Weekly specific articles if any)
          </p>
          
          <h2>Methods Outline </h2>
          <p>Since our project is ethics-based rather than applications-based, much of the research process will involve reading academic papers about deep
              learning and recommendations. Thus, the tools we’ll be using most concern how to extract important information from papers and how to find relevant 
              sources. For the latter, we’ve used databases like jstor and Google Scholar as well as the Works Cited section of papers we find particularly useful. 
              For the former, we are practicing synthesizing information and identifying the most helpful information (e.g. reading the first sentence of each paragraph 
              first) for papers on sometimes more advanced technical concepts. We’ll also be using concepts like CNNs and RNNs from class and Professor Clark’s help to 
              aid our understanding of these research articles.</p>
          
          
          <h2>Discussion Outline </h2>
          <h4>What data will we present? </h4>
            <p>We will be presenting overviews and analyses of existing research papers concerning recommendation algorithms, ranging from 
                collaborative filtering to convolutional neural networks strategies. We will look at the recommendation framework of Auralist, 
                which aims to add ‘serendipity’ into the recommendation process for music.</p>
          
          <p>We’ll also study “heat-spreading” algorithms, which aim to factor in the similarity of users and objects and mitigate echo chambers 
              of recommendations by intentionally diffusing elements across the user-object network/matrix.</p>
          
          <h4>How you we interpret/evaluate your data?</h4>
            <p>We’ll place our analyses of the papers’ data and outcomes and discuss these outcomes within an ethical and “practical” context, focusing 
                on the so-called tradeoff between diversity and accuracy with algorithmic recommendations by connecting to broader psychological and philosophical 
                questions and also tying these outcomes to a concrete dissection of key mathematical/deep learning concepts. For instance, we’ll be explaining and 
                evaluating the role of convolutional neural networks with audio inputs in creating filters for content-based recommendation algorithms.</p>
          
          <h4>How does our work compare to others?</h4>
            <p>Our analysis aims to contribute to the existing attempts to define and address the problems of diversity that stem from recommendation systems. While 
                we’ll target Spotify’s recommendations specifically in order to hone our own analyses, we will also contextualize our ideas and reflections among the0
                broader usage of recommendations, e.g. various types of entertainment consumption, social media, search engine, and digital news algorithms.</p>
          
          <h4>How will we prove our point?</h4>
            <p>We will use the points raised in the papers directly related to recommendation algorithms in combination with background papers that analyse the 
                characteristics of these algorithms to support our claims.</p>



           
    
      </div>
    </div>
  </body>
