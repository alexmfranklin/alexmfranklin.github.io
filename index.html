
<head>
    <meta charset='UTF-8'/>
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel='stylesheet' href='styles.css'/>
    <link href="//db.onlinewebfonts.com/c/86e4910dca09b21de768cb0714d40970?family=Photina" rel="stylesheet" type="text/css"/>
    <title>Becky and Alex's 152 Project Introduction and Related Works</title>
    <link rel="shortcut icon" type="image/x-icon" href="favicon.ico">
  </head>
  
  <body>
    <div class="main">
      <sidebar>
      </sidebar>
      <div class="page">
        <h2>Neural Networks Introduction and Related Works</h2>
        <h3>An ethical investigation into Spotify recommendations</h3> 
        <p>Becky Zhang and Alex Franklin | March 17, 2021</p>
          
          <p> 
              Much of our consumption of music is dictated by the algorithms and models behind streaming service recommendations, which are impacted by the user data that they collect. The architecture of these models, and biases in their data, has real-life implications on what music is played. To investigate these implications, we need to understand what models are used by Spotify, as well as what data is collected and how it is used.
          </p>
          <p>
              The three methods Spotify uses in its recommendation system are collaborative filtering, natural language processing (NLP), and content-based models. Collaborative filtering is content-agnostic, meaning it doesn’t use information related to the music itself, but instead looks at the consumption patterns associated with it. NLP uses song titles, artists, and other textual evidence such as summaries, reviews, tags, etc. to inform its recommendations. Content-based methods use the audio signal of the music to create models, for example training a convolutional neural network (CNN) to recognize certain patterns in the music itself.
          </p>
          <p>
              One challenge that recommendation algorithms face is the positive feedback loop wherein existing user data for certain songs/artists help to drive users toward the very same content (thus generating more data which does the same, and so on so forth). The lack of data for less popular or newer music is called the “cold start problem”, which renders certain songs and artists as outliers that are less easily recommendable by collaborative filtering or NLP models. One solution to this is to include the use of CNNs in addition to collaborative filtering and NLP, and sharpening their capabilities to identify outliers and edge cases. 
          </p>
          <p>
              Another challenge is a lack of access to what Spotify’s neural networks actually look like. We aim to counter this by looking into a variety of applications for content-based models that similarly take audio fragment inputs and learning about what their biases or flaws are. Additionally, we’ll investigate NLP and collaborative filtering and how their developers have tried to combat their blindspots. We will also analyze a long blog post by a former Spotify intern about their insider knowledge on the company’s NNs, and relevant research papers that make use of Spotify’s data.
          </p>
          <p>
              We will first have to develop a more concrete understanding of how these neural networks are functioning (what kind of data and tools they're using) and the goals and decision-making processes of Spotify's development team, to the best of our ability. We will review available research related to Spotify’s recommendation procedures and examine them through a technical and ethical lens. Our hope is to unpack how Spotify uses neural networks to generate music recommendations; identify key blind spots and biases; and assess the broader ethical implications of these, proposing solutions where possible.
          </p>
        

      
      </div>
    </div>
  </body>
